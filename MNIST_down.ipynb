{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//Copyright (c) Microsoft Corporation. All rights reserved. //Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import warnings\n",
    "import PrivacyGAN as pg \n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance\n",
    "X_c = []\n",
    "y_c = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    K.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gen = pg.MNIST_Generator(optim=optim)\n",
    "    dis = pg.MNIST_Discriminator(optim=optim)\n",
    "    \n",
    "    #learn generator per digit \n",
    "    (generator, _, _, _) = pg.SimpGAN(X, generator = gen, discriminator = dis, \n",
    "                                      optim = optim, \n",
    "                                      epochs = 200, batchSize = 256)\n",
    "    \n",
    "    noise = np.random.normal(0, 1, size=[len(X), 100])\n",
    "    X_c += [generator.predict(noise)]\n",
    "    y_c += [i]*len(X)\n",
    "    \n",
    "X_c = np.concatenate(X_c)    \n",
    "y_c = np.array(y_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c))\n",
    "np.random.shuffle(arr)\n",
    "X_c = X_c[arr]\n",
    "y_c = y_c[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "K.clear_session()\n",
    "y_tr = keras.utils.to_categorical(y_c, 10)\n",
    "y_t = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = X_c.reshape(X_c.shape[0], 1, 28, 28)\n",
    "x_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(1,28, 28)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification accuracy on test set\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_0 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "K.clear_session()\n",
    "y_tr = keras.utils.to_categorical(y_train, 10)\n",
    "y_t = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = X_train.reshape(X_c.shape[0], 1, 28, 28)\n",
    "x_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(1,28, 28)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification accuracy on test set\n",
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_1 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrivGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance\n",
    "X_c2 = []\n",
    "y_c2 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    K.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generators = [pg.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5)),\n",
    "                  pg.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    discriminators = [pg.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "                      ,pg.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    pDisc = pg.MNIST_DiscriminatorPrivate(OutSize = 2, \n",
    "                                          optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    (generators, _, _, _, _, _)= pg.privGAN(X, epochs = 200, \n",
    "                                                                               disc_epochs=50,\n",
    "                                                                               batchSize=256,\n",
    "                                                                               generators = generators, \n",
    "                                                                               discriminators = discriminators,\n",
    "                                                                               pDisc = pDisc,\n",
    "                                                                               optim = optim,\n",
    "                                                                               privacy_ratio = 1.0)    \n",
    "    \n",
    "    noise1 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    noise2 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    X_c2 += [generators[0].predict(noise1)]\n",
    "    X_c2 += [generators[1].predict(noise2)]\n",
    "    y_c2 += [i]*(len(noise1) + len(noise2))\n",
    "    \n",
    "X_c2 = np.concatenate(X_c2)    \n",
    "y_c2 = np.array(y_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c2))\n",
    "np.random.shuffle(arr)\n",
    "X_c2 = X_c2[arr]\n",
    "y_c2 = y_c2[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model\n",
    "K.clear_session()\n",
    "y_tr = keras.utils.to_categorical(y_c2, 10)\n",
    "y_t = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = X_c2.reshape(X_c2.shape[0], 1, 28, 28)\n",
    "x_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(1,28, 28)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_tr,\n",
    "          batch_size=256,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_2 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance of different CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0,1,2],[r_1[1],r_0[1],r_2[1]])\n",
    "plt.xticks([0,1,2],['Real','GAN','privGAN (1.0)'], rotation=45)\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
